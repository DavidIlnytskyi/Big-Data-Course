{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e81411b-77f7-4f34-903b-b9be42da1433",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93bc7586-7fb5-4078-bf49-a318ee616714",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, NumericType, IntegerType\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e987456c-41a2-4c1d-b496-c64281bdab7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1f9fcd9-43dd-4679-a429-de89aab3b4ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_missing_stats_df(df):\n",
    "    total_rows = df.count()\n",
    "    \n",
    "    missing_counts = []\n",
    "    \n",
    "    for col_name, col_type in df.dtypes:\n",
    "        # For string columns, check for null OR empty strings\n",
    "        if col_type == 'string':\n",
    "            missing_expr = F.sum(\n",
    "                F.when(F.col(col_name).isNull() | (F.col(col_name) == \"\"), 1).otherwise(0)\n",
    "            )\n",
    "        # For numeric columns, only check for null (not empty strings)\n",
    "        else:\n",
    "            missing_expr = F.sum(F.when(F.col(col_name).isNull(), 1).otherwise(0))\n",
    "        \n",
    "        missing_counts.append(missing_expr.alias(col_name))\n",
    "    \n",
    "    # Collect results\n",
    "    missing = (\n",
    "        df.select(missing_counts)\n",
    "        .toPandas()\n",
    "        .T\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"column\", 0: \"missing_count\"})\n",
    "    )\n",
    "    \n",
    "    missing[\"missing_percent\"] = (missing[\"missing_count\"] / total_rows) * 100\n",
    "    missing[\"data_type\"] = [dict(df.dtypes)[col] for col in missing[\"column\"]]\n",
    "    \n",
    "    # Sort by missing count descending for better visibility\n",
    "    missing = missing.sort_values(\"missing_count\", ascending=False)\n",
    "    \n",
    "    return missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82cfb89c-7362-460d-bbac-970886dcb0b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_rows_with_missing_values(df, include_missing_flags=True):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame containing only rows that have at least one missing value.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: Input DataFrame\n",
    "    - include_missing_flags: If True, adds boolean columns showing which fields are missing\n",
    "    \"\"\"\n",
    "    # Create conditions and flag columns\n",
    "    missing_conditions = []\n",
    "    flag_columns = []\n",
    "    \n",
    "    for col_name, col_type in df.dtypes:\n",
    "        if col_type == 'string':\n",
    "            condition = F.col(col_name).isNull() | (F.col(col_name) == \"\")\n",
    "        else:\n",
    "            condition = F.col(col_name).isNull()\n",
    "        \n",
    "        missing_conditions.append(condition)\n",
    "        flag_columns.append(F.when(condition, True).otherwise(False).alias(f\"missing_{col_name}\"))\n",
    "    \n",
    "    # Combined condition for filtering\n",
    "    combined_condition = missing_conditions[0]\n",
    "    for condition in missing_conditions[1:]:\n",
    "        combined_condition = combined_condition | condition\n",
    "    \n",
    "    # Filter rows with missing values\n",
    "    missing_rows_df = df.filter(combined_condition)\n",
    "    \n",
    "    # Add missing flags if requested\n",
    "    if include_missing_flags:\n",
    "        missing_rows_df = missing_rows_df.select(\n",
    "            \"*\", *flag_columns\n",
    "        )\n",
    "    \n",
    "    return missing_rows_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d598238-1f0f-4917-a194-2e3368c64464",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4a2d102-a119-4622-b49c-9b5e78cd7ee6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    'host_id','host_since','host_is_superhost','latitude','longitude','property_type','room_type','accommodates','bathrooms','bathrooms_text','bedrooms','beds','amenities','price','minimum_nights','maximum_nights', 'number_of_reviews','review_scores_rating','license','instant_bookable','reviews_per_month'\n",
    "]\n",
    "\n",
    "df = spark.read.table('airbnb.raw.listings').select(columns_to_keep)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "337ca70d-f036-47b0-a391-c9c9f37c8070",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a1b4379-f8c5-4379-ac0b-f3106cb91b07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35908c8c-400a-4683-a1d9-aa2e9baa36d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0610a83-63ae-4072-84ef-23ccd447f8d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_missing_stats = get_missing_stats_df(df)\n",
    "display(df_missing_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53fb8938-b5da-4757-b39c-bfd922ab2c23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "As _Bathrooms_ column consists of only null rows, we will remove that to get clearer data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ee4f6b0-53be-495e-aebb-d04da86c30d8",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1761078502878}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'host_id','host_since','host_is_superhost','latitude','longitude','property_type','room_type','accommodates', 'bathrooms_text','bedrooms','beds','amenities','price','minimum_nights','maximum_nights', 'number_of_reviews','review_scores_rating','license','instant_bookable','reviews_per_month'\n",
    "]\n",
    "\n",
    "df = df.select(columns)\n",
    "df_missing_rows = get_rows_with_missing_values(df, include_missing_flags=True)\n",
    "print(f\"Rows with missing values: {df_missing_rows.count()}\")\n",
    "print(f\"Total rows in dataset: {df_missing_rows.count()}\")\n",
    "print(f\"Missing rows percentage: {(df_missing_rows.count() / df_missing_rows.count()) * 100:.2f}%\")\n",
    "\n",
    "# Show sample of missing rows\n",
    "display(df_missing_rows.limit(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc140a82-3f4f-4492-a36c-2df44700aed3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b4d78d7-f04b-4762-a795-5667bc314939",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7189e5e-9757-4729-9a06-9d32af299af1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Subset your dataframe to the relevant columns\n",
    "df_subset = df.select(columns).toPandas()  # Assuming df is a Spark DataFrame\n",
    "\n",
    "# Calculate missing % per column\n",
    "missing_percent = df_subset.isnull().mean() * 100\n",
    "\n",
    "# Filter columns with missing values only\n",
    "missing_percent = missing_percent[missing_percent > 0]\n",
    "\n",
    "# 1. Missing % per column bar plot (only columns with missing data)\n",
    "plt.figure(figsize=(12, 6))\n",
    "missing_percent.plot.bar(color='steelblue')\n",
    "plt.title('Percentage of Missing Values per Column (Non-missing Columns Removed)')\n",
    "plt.ylabel('Percentage Missing (%)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0, 100)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Optional: Missingness by group (property_type here)\n",
    "if 'property_type' in df_subset.columns:\n",
    "    missing_by_group = df_subset.groupby('property_type').apply(lambda x: x.isnull().mean() * 100)\n",
    "    missing_by_group = missing_by_group.drop(columns=['property_type'], errors='ignore')\n",
    "\n",
    "    # Keep only columns that have missingness overall (same columns as above)\n",
    "    missing_by_group = missing_by_group[missing_percent.index]\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    missing_by_group.T.plot(kind='bar', figsize=(14,7), colormap='tab20')\n",
    "    plt.title('Missingness Percentage per Column by Property Type (Non-missing Columns Removed)')\n",
    "    plt.ylabel('Percentage Missing (%)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title='Property Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff43b5db-e05b-4312-9512-7c8c98b0c58a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Correlation between colums missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d230dfb2-2fe0-4cb5-a61a-e36b791ed5f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "null_indicator_df = df.select([\n",
    "    F.when(F.col(col).isNull(), 0).otherwise(1).alias(col) \n",
    "    for col in df.columns\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fa07e56-2c2b-4e2e-8890-1084111d2514",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Convert to vector column for ML correlation\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=null_indicator_df.columns, \n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "vector_df = assembler.transform(null_indicator_df)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = Correlation.corr(vector_df, \"features\").head()[0]\n",
    "\n",
    "# Convert to pandas for better visualization\n",
    "corr_array = corr_matrix.toArray()\n",
    "corr_pd = pd.DataFrame(corr_array, \n",
    "                      columns=null_indicator_df.columns, \n",
    "                      index=null_indicator_df.columns)\n",
    "\n",
    "print(corr_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2aa17e4c-e8c6-43b7-8d9b-c19611534cf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a filtered correlation matrix (only strong correlations)\n",
    "threshold = 0\n",
    "filtered_corr = corr_pd.where(abs(corr_pd) > threshold)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(filtered_corr, \n",
    "            annot=True, \n",
    "            cmap='RdBu_r', \n",
    "            center=0,\n",
    "            fmt='.2f',\n",
    "            square=True)\n",
    "plt.title(f'Missing Data Correlation (|r| > {threshold})')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b264b315-a19a-4d40-960d-dafc09ede159",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Price column analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de4430ab-5a52-4f94-aeb5-33067b5ee461",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "patterns = {\n",
    "    'Dollar with decimal and commas': r'^\\$\\d{1,3}(,\\d{3})+\\.\\d{2}$',  # e.g. $5,000.00\n",
    "    'Dollar with decimal': r'^\\$\\d+\\.\\d{2}$',                          # e.g. $150.00\n",
    "    'No dollar with decimal': r'^\\d+\\.\\d{2}$',                         # e.g. 150.00\n",
    "    'Dollar no decimal': r'^\\$\\d+$',                                   # e.g. $150\n",
    "    'No dollar no decimal': r'^\\d+$',                                  # e.g. 150\n",
    "    'Dollar with commas no decimal': r'^\\$\\d{1,3}(,\\d{3})+$',          # e.g. $1,500\n",
    "}\n",
    "\n",
    "def detect_pattern_expr():\n",
    "    expr = None\n",
    "    for name, regex in patterns.items():\n",
    "        condition = F.regexp_extract(F.col('price').cast('string'), regex, 0) != ''\n",
    "        if expr is None:\n",
    "            expr = F.when(condition, name)\n",
    "        else:\n",
    "            expr = expr.when(condition, name)\n",
    "    expr = expr.otherwise('Other')\n",
    "    return expr\n",
    "\n",
    "df_with_pattern = df.withColumn('pattern', detect_pattern_expr())\n",
    "\n",
    "pattern_counts = (\n",
    "    df_with_pattern.groupBy('pattern')\n",
    "    .count()\n",
    "    .orderBy(F.desc('count'))\n",
    ")\n",
    "\n",
    "pattern_counts_pd = pattern_counts.toPandas()\n",
    "\n",
    "# Plot bar chart\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(pattern_counts_pd['pattern'], pattern_counts_pd['count'], color='skyblue')\n",
    "plt.title('Price Pattern Frequency')\n",
    "plt.xlabel('Price Pattern')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fb289e3-8228-490b-9fe6-65dca9d04775",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "As we can see, there is no other currencies except dollars and 2 templates, so price is consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8148d898-4eb7-44ac-8e3f-6bef2bfb4d9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "vizualize.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
